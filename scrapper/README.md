# Scrapper
- Spiders are classes which define how a certain site (or a group of sites) will be scraped, including how to perform the crawl (i.e. follow links) and how to extract structured data from their pages (i.e. scraping items). [Read more...](https://docs.scrapy.org/en/latest/topics/spiders.html#:~:text=Spiders%20are%20classes%20which%20define,pages%20(i.e.%20scraping%20items))
- This file contains the script to perform web-scrapping on NCSU jobs search portal. The script for web-scrapping is written using Chrome driver and Selenium.
## Run Instructions
```
- insert driver code in "myclient = pymongo.MongoClient(<mongodb driver>)
- python jobscrapper.py
```

